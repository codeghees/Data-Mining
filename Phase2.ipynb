{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use three models to predict our data.\n",
    "1. Logistic Regression\n",
    "2. Neural Network\n",
    "3. Decision Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading our processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"Input.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"Output.pickle\",\"rb\")\n",
    "Y = pickle.load(pickle_in)\n",
    "# print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['order_number', 'add_to_cart_order', 'department_id',\n",
      "       'days_since_prior_order', 'order_hour_of_day', 'order_dow',\n",
      "       'product_id', 'aisle_id'],\n",
      "      dtype='object')\n",
      "(9462265, 8)\n",
      "(9462265,)\n"
     ]
    }
   ],
   "source": [
    "print(X.keys())\n",
    "\n",
    "x = X.values\n",
    "print(x.shape)\n",
    "y = Y.values\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size = 0.3)\n",
    "logiR = LogisticRegression(solver = 'lbfgs')\n",
    "logiR.fit(xTrain, yTrain)\n",
    "\n",
    "yPrediction = logiR.predict(xTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy after logistic regression is =  69.65216227260558\n"
     ]
    }
   ],
   "source": [
    "score = logiR.score(xTest, yTest)\n",
    "print(\"The accuracy after logistic regression is = \", score*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing a test/train split, we use logistic Regression library of sklearn and estimate a model. That model gives us a 69.6 percent accuracy on the test data.\n",
    "The solver used was lbfgs.\n",
    "The variable being predicted is which product would be reordered against all the attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made a network of 4 normal layers and 3 dropout layers.\n",
    "The input was the 8 attributes we selected and the output was whether it will be reordered or not.\n",
    "The drop out layer was added to avoid overtraining.\n",
    "Batch Normalization normalizes the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.\n",
    "This helped improve accuracy by 30 percent.\n",
    "The weights are attached. \n",
    "The highest accuracy was 72 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x0000018A4CC7A358>>\n",
      "WARNING:tensorflow:From C:\\Users\\Moughees\\AppData\\Local\\Continuum\\anaconda3\\envs\\DIP_DEMO\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(6623585, 8)\n",
      "(6623585, 2)\n",
      "WARNING:tensorflow:From C:\\Users\\Moughees\\AppData\\Local\\Continuum\\anaconda3\\envs\\DIP_DEMO\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Moughees\\AppData\\Local\\Continuum\\anaconda3\\envs\\DIP_DEMO\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "6623585/6623585 [==============================] - 232s 35us/step - loss: 0.5513 - acc: 0.7172\n",
      "6623585/6623585 [==============================] - 66s 10us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5415709088398101, 0.7228571838360478]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Source = https://gist.github.com/stevhliu/2dad7416cfb9eec107f3e5748cadbb2b#file-basicnn-py\n",
    "m1 = Sequential()\n",
    "m1.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                          beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros'))\n",
    "m1.add(Dense(64, activation='relu', input_dim=8))\n",
    "m1.add(Dropout(0.25))\n",
    "m1.add(Dense(64, activation='relu'))\n",
    "m1.add(Dropout(0.25))\n",
    "m1.add(Dense(64, activation='relu'))\n",
    "m1.add(Dropout(0.25))\n",
    "m1.add(Dense(64, activation='relu'))\n",
    "m1.add(Dense(2, activation='softmax'))\n",
    "print(m1.summary)\n",
    "# compile the model\n",
    "m1.compile(loss='categorical_crossentropy',\n",
    "           optimizer='adam',\n",
    "           metrics=['accuracy'])\n",
    "\n",
    "# fit the model\n",
    "y_binary = np_utils.to_categorical(yTrain)\n",
    "print(xTrain.shape)\n",
    "print(y_binary.shape)\n",
    "m1.fit(xTrain, y_binary,\n",
    "       epochs=1,\n",
    "       batch_size = 128)\n",
    "\n",
    "# evaluate the model\n",
    "m1.evaluate(xTrain, y_binary, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2838680/2838680 [==============================] - 28s 10us/step\n"
     ]
    }
   ],
   "source": [
    "y_test = np_utils.to_categorical(yTest)\n",
    "Results = m1.evaluate(xTest, y_test, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.save_weights('weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the neural network is =  72.29543308863545\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of the neural network is = \",  Results[1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.7 0.6 ... 0.4 0.9 0. ]\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=10)  \n",
    "regressor.fit(xTrain, yTrain)  \n",
    "y_pred = regressor.predict(xTest)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the Decision Tree is =  69.62450857440783\n"
     ]
    }
   ],
   "source": [
    "# ypred = np_utils.to_categorical(y_pred)\n",
    "# print(map(round,y_pred))\n",
    "roundedlist = list(map(round,y_pred))\n",
    "# print()\n",
    "# print(yTest)\n",
    "print(\"The accuracy for the Decision Tree is = \" , accuracy_score(yTest, roundedlist)*100) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 734330  426438]\n",
      " [ 435825 1242087]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63   1160768\n",
      "           1       0.74      0.74      0.74   1677912\n",
      "\n",
      "   micro avg       0.70      0.70      0.70   2838680\n",
      "   macro avg       0.69      0.69      0.69   2838680\n",
      "weighted avg       0.70      0.70      0.70   2838680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yTest,roundedlist))  \n",
    "print(classification_report(yTest,roundedlist))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model we used was a Decision forest.\n",
    "We again used an SKlearn library and 10 decision trees were made. The accuracy was around 69 percent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
